{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a5cf56",
   "metadata": {},
   "source": [
    "## LANE LINE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b74ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7fa120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cafb5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect lane lines\n",
    "def detect_lane_lines(image):\n",
    "    # Define region of interest (ROI)\n",
    "    height, width = image.shape\n",
    "    roi_vertices = [(0, height), (width / 2, height / 2), (width, height)]\n",
    "    \n",
    "    # Create a mask to focus on the ROI\n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.fillPoly(mask, [np.array(roi_vertices, np.int32)], 255)\n",
    "    \n",
    "    # Apply bitwise AND to get the ROI\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    \n",
    "    # Use Hough Line Transform to detect lines\n",
    "    lines = cv2.HoughLinesP(masked_image, 1, np.pi / 180, 50, minLineLength=100, maxLineGap=50)\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f54b569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw detected lane lines on the original image\n",
    "def draw_lane_lines(image, lines):\n",
    "    line_image = np.zeros_like(image)\n",
    "    \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(line_image, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "    \n",
    "    return cv2.addWeighted(image, 0.8, line_image, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b9fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Capture video from a camera or load an image\n",
    "    cap = cv2.VideoCapture('test_video.mp4')  # Replace with your video file or camera source\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Preprocess the frame\n",
    "        edges = preprocess_image(frame)\n",
    "        \n",
    "        # Detect lane lines\n",
    "        lines = detect_lane_lines(edges)\n",
    "        \n",
    "        # Draw lane lines on the frame\n",
    "        lane_lines = draw_lane_lines(frame, lines)\n",
    "        \n",
    "        # Display the result\n",
    "        cv2.imshow('Lane Detection', lane_lines)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e6993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
